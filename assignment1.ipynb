{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: k-nearest neighbors (Programming) \n",
    "\n",
    "Only use the already imported libraries `numpy` and `matplotlib.pyplot` for the assignment. Do not import any other library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> *Write*\n",
    "* *names* \n",
    "* *matr. nr.* \n",
    "* *study program*\n",
    "* *B.Sc./M.Sc.*\n",
    "Dao Khanh Duy_3591406_INFOTECH_M.Sc.\n",
    "Harshal Sanjay Nandigramwar_INFOTECH_M.Sc.\n",
    "Xiwen Feng_3219649_Natural Language Processing_B.Sc.\n",
    "*of all assignment group participants here.* (double klick here to edit)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required packages and dataset. Do not modify.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def load_breast_cancer_dataset():\n",
    "    from sklearn import datasets\n",
    "    breast_cancer = datasets.load_breast_cancer()\n",
    "    X = breast_cancer.data\n",
    "    y = breast_cancer.target\n",
    "    return X, y\n",
    "    \n",
    "X, y = load_breast_cancer_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Visualization and Preprocessing\n",
    "\n",
    "1) Explain the content of the dataset in few words. What are the input features? What is the classification target? Check out: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> *Write your response here.* (double klick here to edit)\n",
    "Dataset consists of 569 instances with 32 input features:\n",
    "a) radius (mean of distances from center to points on the perimeter)\n",
    "b) texture (standard deviation of gray-scale values)\n",
    "c) perimeter\n",
    "d) area\n",
    "e) smoothness (local variation in radius lengths)\n",
    "f) compactness (perimeter^2 / area - 1.0)\n",
    "g) concavity (severity of concave portions of the contour)\n",
    "h) concave points (number of concave portions of the contour)\n",
    "i) symmetry\n",
    "j) fractal dimension (\"coastline approximation\" - 1\n",
    "\n",
    "Classification target is diagnosis of digitized image of a fine needle aspirate (FNA) of a breast mass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Compute and print the following statistics about the dataset:\n",
    "  - Number of samples\n",
    "  - Number of samples per class\n",
    "  - Mean and standard deviation for each input feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n",
      "y:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      "Number of samples: 569\n",
      "\n",
      "Number of samples of class 0: 212\n",
      "Number of samples of class 1: 357\n",
      "Mean of data column 0 : 14.127291739894552\n",
      "Standard Deviation of data column 0 : 3.520950760711062\n",
      "\n",
      "Mean of data column 1 : 19.289648506151142\n",
      "Standard Deviation of data column 1 : 4.297254637090421\n",
      "\n",
      "Mean of data column 2 : 91.96903339191564\n",
      "Standard Deviation of data column 2 : 24.27761929305318\n",
      "\n",
      "Mean of data column 3 : 654.8891036906855\n",
      "Standard Deviation of data column 3 : 351.60475406323\n",
      "\n",
      "Mean of data column 4 : 0.0963602811950791\n",
      "Standard Deviation of data column 4 : 0.014051764066591203\n",
      "\n",
      "Mean of data column 5 : 0.10434098418277679\n",
      "Standard Deviation of data column 5 : 0.05276632912535515\n",
      "\n",
      "Mean of data column 6 : 0.0887993158172232\n",
      "Standard Deviation of data column 6 : 0.07964972534603185\n",
      "\n",
      "Mean of data column 7 : 0.04891914586994728\n",
      "Standard Deviation of data column 7 : 0.03876873246147477\n",
      "\n",
      "Mean of data column 8 : 0.18116186291739894\n",
      "Standard Deviation of data column 8 : 0.027390180864268532\n",
      "\n",
      "Mean of data column 9 : 0.06279760984182776\n",
      "Standard Deviation of data column 9 : 0.007054155881537345\n",
      "\n",
      "Mean of data column 10 : 0.40517205623901575\n",
      "Standard Deviation of data column 10 : 0.27706894152536526\n",
      "\n",
      "Mean of data column 11 : 1.2168534270650264\n",
      "Standard Deviation of data column 11 : 0.551163426903576\n",
      "\n",
      "Mean of data column 12 : 2.8660592267135327\n",
      "Standard Deviation of data column 12 : 2.0200770991455244\n",
      "\n",
      "Mean of data column 13 : 40.337079086116\n",
      "Standard Deviation of data column 13 : 45.45101341563996\n",
      "\n",
      "Mean of data column 14 : 0.007040978910369069\n",
      "Standard Deviation of data column 14 : 0.0029998783671144756\n",
      "\n",
      "Mean of data column 15 : 0.025478138840070295\n",
      "Standard Deviation of data column 15 : 0.01789243586828196\n",
      "\n",
      "Mean of data column 16 : 0.03189371634446397\n",
      "Standard Deviation of data column 16 : 0.030159523121970472\n",
      "\n",
      "Mean of data column 17 : 0.011796137082601054\n",
      "Standard Deviation of data column 17 : 0.006164860746471701\n",
      "\n",
      "Mean of data column 18 : 0.02054229876977153\n",
      "Standard Deviation of data column 18 : 0.008259104387588135\n",
      "\n",
      "Mean of data column 19 : 0.0037949038664323374\n",
      "Standard Deviation of data column 19 : 0.0026437447504047374\n",
      "\n",
      "Mean of data column 20 : 16.269189806678387\n",
      "Standard Deviation of data column 20 : 4.828992576060772\n",
      "\n",
      "Mean of data column 21 : 25.677223198594024\n",
      "Standard Deviation of data column 21 : 6.1408543185890005\n",
      "\n",
      "Mean of data column 22 : 107.26121265377857\n",
      "Standard Deviation of data column 22 : 33.57300156682593\n",
      "\n",
      "Mean of data column 23 : 880.5831282952548\n",
      "Standard Deviation of data column 23 : 568.8564589532671\n",
      "\n",
      "Mean of data column 24 : 0.13236859402460457\n",
      "Standard Deviation of data column 24 : 0.022812356935544644\n",
      "\n",
      "Mean of data column 25 : 0.25426504393673116\n",
      "Standard Deviation of data column 25 : 0.15719817109455372\n",
      "\n",
      "Mean of data column 26 : 0.27218848330404216\n",
      "Standard Deviation of data column 26 : 0.20844087461170602\n",
      "\n",
      "Mean of data column 27 : 0.11460622319859401\n",
      "Standard Deviation of data column 27 : 0.06567455451119314\n",
      "\n",
      "Mean of data column 28 : 0.2900755711775044\n",
      "Standard Deviation of data column 28 : 0.06181307854455481\n",
      "\n",
      "Mean of data column 29 : 0.0839458172231986\n",
      "Standard Deviation of data column 29 : 0.01804538930859499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Implement your solution here.\n",
    "print('X:')\n",
    "print(X)\n",
    "print('y:')\n",
    "print(y)\n",
    "print('Number of samples:',len(X))\n",
    "print()\n",
    "print('Number of samples of class 0:',np.sum(y==0))\n",
    "print('Number of samples of class 1:',np.sum(y==1))\n",
    "i = 0\n",
    "for i in range(len(X[0])):\n",
    "    print('Mean of data column',i ,':',np.mean(X[:,i]))\n",
    "    print('Standard Deviation of data column',i,':',np.std(X[:,i]))\n",
    "    print()\n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Visualize the variables *radius (mean)* and *texture (mean)* in a scatter plot (*radius (mean)* on the x-axis, *texture (mean)* on the y-axis). Color each point of the plot according to its class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Implement your solution here.\n",
    "class0 = np.where(y == 0)\n",
    "class1 = np.where(y == 1)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title('scatter plot')\n",
    "ax.scatter(X[class0,0],X[class0,2],label = '$class0$')\n",
    "ax.scatter(X[class1,0],X[class1,2],label = '$class1$')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Split the dataset randomly into training and test data. 70% of data should be used for training and 30% should be used for testing. Implement the function `train_test_split`. Do not modify the interface of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(X, y):\n",
    "    \"\"\"\n",
    "    Returns X_train, X_test, y_train, y_test, \n",
    "        where X_train and X_test are the input features of the training and test set,\n",
    "        and y_train and y_test are the class labels of the training and test set.\n",
    "    \"\"\"\n",
    "    threshold = int(0.7*X.shape[0])\n",
    "    rnd_idx = np.random.permutation(X.shape[0])\n",
    "    \n",
    "    X_train = X[rnd_idx[:threshold]]\n",
    "    X_test = X[rnd_idx[threshold:]]\n",
    "    y_train = y[rnd_idx[:threshold]]\n",
    "    y_test = y[rnd_idx[threshold:]]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "assert (X_train.shape[0] + X_test.shape[0]) == X.shape[0]\n",
    "assert (y_train.shape[0] + y_test.shape[0]) == y.shape[0]\n",
    "assert X_train.shape[1] == X_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) kNN uses a distance measure to identify close neighbors. If the input features are not of the same scale, the distance is not as meaningful, which can negatively impact classification performance. Perform min-max scaling (i.e. scale the values of the input features in such a way that their range is from 0 to 1) on the training and test data. Remember that you should only use information from the training data to perform the scaling on both data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your solution here\n",
    "def min_max_scaling(X_train, X_test):\n",
    "    X_column =  np.size(X_train,1)\n",
    "    for i in range(0,X_column):\n",
    "        a=max(X_train[:,i])\n",
    "        X_train[:,i]=X_train[:,i]/a\n",
    "        X_test[:,i]=X_test[:,i]/a\n",
    "    return X_train,X_test\n",
    "\n",
    "X_train,X_test= min_max_scaling(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: k-nearest neighbors \n",
    "*Choose classes randomly if weights are equal for multiple classes*\n",
    "\n",
    "**For B.Sc. Data Science:**  \n",
    "\n",
    "Implement the kNN algorithm with uniform weighting and arbitrary `k`. Fill out the `predict` method of class `KNearestNeighbors`. \n",
    "\n",
    "Use Euclidean distance to determine the nearest neighbors.\n",
    "You can ignore the optional parameter `weights`, which is provided as a field in the kNN class.\n",
    "\n",
    "**For all students other than B.Sc. Data Science:**\n",
    "\n",
    "Implement the kNN algorithm with uniform and distance-based weighting and arbitrary `k`.\n",
    "Fill out the `predict` method of class `KNearestNeighbors`.\n",
    "\n",
    "The parameter `weights` will either contain the string `uniform` or `distance`. \n",
    "- If the value is `uniform`, the classifier should use the Euclidean distance for determining nearest neighbors and uniform weighting. \n",
    "- If the value is a `distance`, the classifier should use the Euclidean distance for determining neares neighbors and perform distance-weighted classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbors(object):\n",
    "    def __init__(self, k, weights='uniform'):\n",
    "        self.k = k\n",
    "        self.weights = weights\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        This functions saves the training data to be used during the prediction.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Returns a vector of shape (n,) if X has shape (n,d), \n",
    "        where n is the number of samples and d is the number of features.\n",
    "        \"\"\"\n",
    "        # Implement your solution here.\n",
    "        h=np.array([],dtype=np.int64) \n",
    "        \n",
    "        for i in range(0,len(X[:,1])):\n",
    "            a=np.array([])\n",
    "            for j in range(0,len(self.X[:,1])):\n",
    "                if self.weights == 'uniform':\n",
    "                    b=euclidean_distance(X[i,:],self.X[j,:])\n",
    "                else:\n",
    "                     b=self.weights(X[i,:],self.X[j,:])\n",
    "                a=np.append(a,b)\n",
    "            index=np.argsort(a)\n",
    "            kindex=np.array([],dtype=np.int64)   \n",
    "            for ii in range(0,self.k):\n",
    "                kindex=np.append(kindex,self.y[index[ii]])\n",
    "            h=np.append(h,np.argmax(np.bincount(kindex)))\n",
    "        return h\n",
    "        \n",
    "\n",
    "    \n",
    "def euclidean_distance(x1, x2):\n",
    "    \"\"\"\n",
    "    Given vectors x1 and x2 with shape (n,) returns distance between vectors as float.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((x1 - x2)*(x1 - x2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Evaluation\n",
    "\n",
    "1) Implement functions to compute precision, recall and F1-score. `y_pred` and `y_true` are the vectors of predicted and true class labels respectively with shape `(n,)`, where `n` is the number of samples. Each function should return a float containing the corresponding score. It is advisable to implement a function for the confusion matrix and reuse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_pred, y_true):\n",
    "    # Implement your solution here.\n",
    "    c_Num=np.bincount(y_true)\n",
    "    p_Num=np.bincount(y_pred)\n",
    "    p_V=np.array([],dtype=np.int64)\n",
    "    for i in range(0,len(c_Num)):\n",
    "        aa=np.argwhere((y_pred==y_true) & (y_pred==i))\n",
    "        precision=aa.size/p_Num[i]\n",
    "        p_V=np.append(p_V,precision)\n",
    "    return p_V  \n",
    "        \n",
    "\n",
    "def recall(y_pred, y_true):\n",
    "    # Implement your solution here.\n",
    "    c_Num=np.bincount(y_true)\n",
    "    p_Num=np.bincount(y_pred)\n",
    "    r_V=np.array([],dtype=np.int64)\n",
    "    for i in range(0,len(c_Num)):\n",
    "        aa=np.argwhere((y_pred==y_true) & (y_pred==i))\n",
    "        recall=aa.size/c_Num[i]\n",
    "        r_V=np.append(r_V,recall)\n",
    "    return r_V  \n",
    "\n",
    "\n",
    "def f1score(y_pred, y_true):\n",
    "    # Implement your solution here.\n",
    "    p_V=precision(y_pred, y_true)\n",
    "    r_V=recall(y_pred, y_true)\n",
    "    f_V=np.array([],dtype=np.int64)\n",
    "    for i in range(0,len(p_V)):\n",
    "        f=2*r_V[i]*p_V[i]/(r_V[i]+p_V[i])\n",
    "        f_V=np.append(f_V,f)\n",
    "    return f_V\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Evaluate the performance of kNN with uniform weighting on the Breast Cancer dataset for `k=1,5,9`. Train each of the `3` classifiers on the training data from Task 1. Perform the predictions on both the training and test data. Then compute precision, recall, and F1-score for each model and for both training and test data. Visualize the performance in a plot, what do you observe?\n",
    "\n",
    "**For all students other than B.Sc. Data Science:** \n",
    "\n",
    "Also evaluate the kNN classifier with Euclidean distance-weighting. Compare the performance to uniform-weighting. How does the performance change compared to uniform weighting for each `k`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Test precision k= 1  [0.91935484 0.97247706]\n",
      "X_Test recall k= 1  [0.95       0.95495495]\n",
      "X_Test f1score k= 1  [0.93442623 0.96363636]\n",
      "X_train precision k= 1  [1. 1.]\n",
      "X_train recall k= 1  [1. 1.]\n",
      "X_train f1score k= 1  [1. 1.]\n",
      "X_Test precision k= 3  [0.93442623 0.97272727]\n",
      "X_Test recall k= 3  [0.95       0.96396396]\n",
      "X_Test f1score k= 3  [0.94214876 0.96832579]\n",
      "X_train precision k= 3  [1.         0.98007968]\n",
      "X_train recall k= 3  [0.96710526 1.        ]\n",
      "X_train f1score k= 3  [0.98327759 0.98993964]\n",
      "X_Test precision k= 5  [0.94915254 0.96428571]\n",
      "X_Test recall k= 5  [0.93333333 0.97297297]\n",
      "X_Test f1score k= 5  [0.94117647 0.96860987]\n",
      "X_train precision k= 5  [0.99315068 0.97222222]\n",
      "X_train recall k= 5  [0.95394737 0.99593496]\n",
      "X_train f1score k= 5  [0.97315436 0.98393574]\n",
      "precision [0.91935484 0.97247706]\n",
      "recall [0.95       0.95495495]\n",
      "f1score [0.93442623 0.96363636]\n"
     ]
    }
   ],
   "source": [
    "# Implement your solution here.\n",
    "for k in [1,3,5]:\n",
    "    erfolg=KNearestNeighbors(k)\n",
    "    erfolg.fit(X_train,y_train)\n",
    "    h=erfolg.predict(X_test)\n",
    "    print('X_Test precision k=',k,'',precision(h, y_test))\n",
    "    print('X_Test recall k=',k,'',recall(h,y_test))\n",
    "    print('X_Test f1score k=',k,'',f1score(h,y_test))\n",
    "    h=erfolg.predict(X_train)\n",
    "    print('X_train precision k=',k,'',precision(h, y_train))\n",
    "    print('X_train recall k=',k,'',recall(h,y_train))\n",
    "    print('X_train f1score k=',k,'',f1score(h,y_train))\n",
    "    \n",
    "def euclidean_distance2(x1, x2):\n",
    "    \"\"\"\n",
    "    Given vectors x1 and x2 with shape (n,) returns distance between vectors as float.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((x1 - x2)*(x1 - x2)))*100/(0.1+np.sqrt(np.sum((x1 - x2)*(x1 - x2))))\n",
    "\n",
    "erfolg=KNearestNeighbors(1,euclidean_distance2)\n",
    "erfolg.fit(X_train,y_train)\n",
    "h=erfolg.predict(X_test)\n",
    "print('precision',precision(h, y_test))\n",
    "print('recall',recall(h,y_test))\n",
    "print('f1score',f1score(h,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> *Write your observations here and report your results.* (double klick here to edit)\n",
    "k bigger means that the results will be more precise. However, k can only get to a limit when we make a distance weighting, here i made an example with the weighting function (100/(0.1+x)),and it can also make results more presice"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
